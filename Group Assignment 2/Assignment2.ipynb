{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT ANALYTICS GROUP ASSIGNMENT #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Members: Brooks Beckelman, Zack Bilderback, Dallas Griffin, Estevan Gonzalez, Sean Kessel, Davis Townsend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "%pylab inline\n",
    "\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp = pd.read_csv('Yelp Data Restaurant Reviews Ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>...</th>\n",
       "      <th>Indian</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Greek</th>\n",
       "      <th>Mediterranean</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Vietnamese</th>\n",
       "      <th>Others</th>\n",
       "      <th>Review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>This location is out of business. I drove by i...</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>= = = = = = CLOSED = = = = = =This JB s locati...</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>This is just a basic (albeit mini) chain greas...</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars  votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "0      1           0            0             0      1         0          0   \n",
       "1      2           2            2             2      1         0          0   \n",
       "2      4           0            0             1      1         0          0   \n",
       "\n",
       "   VeryExpensive  American  Chinese   ...    Indian  Italian  Greek  \\\n",
       "0              0         0        0   ...         0        0      0   \n",
       "1              0         0        0   ...         0        0      0   \n",
       "2              0         0        0   ...         0        0      0   \n",
       "\n",
       "   Mediterranean  Mexican  Thai  Vietnamese  Others  \\\n",
       "0              0        0     0           0       1   \n",
       "1              0        0     0           0       1   \n",
       "2              0        0     0           0       1   \n",
       "\n",
       "                                              Review  rating  \n",
       "0  This location is out of business. I drove by i...     low  \n",
       "1  = = = = = = CLOSED = = = = = =This JB s locati...     low  \n",
       "2  This is just a basic (albeit mini) chain greas...    high  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert rating to high (4,5) or low (1,2,3)\n",
    "yelp['rating'] = np.where(yelp['stars'] >= 4, 'high','low')\n",
    "yelp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train, test = train_test_split(yelp, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train.drop(['stars', 'Review', 'rating'], axis=1)\n",
    "y_train = train['rating']\n",
    "\n",
    "x_test = test.drop(['stars', 'Review', 'rating'], axis=1)\n",
    "y_test = test['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bays Accuracy: 0.6816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb_classifier = bnb.fit(x_train, y_train)\n",
    "bnb_predict = bnb.predict(x_test)\n",
    "bnb_accuracy = bnb.score(x_test, y_test)\n",
    "\n",
    "print 'Bernoulli Naive Bays Accuracy:', bnb_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy: 0.6812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb_classifier = mnb.fit(x_train, y_train)\n",
    "mnb_predict = mnb.predict(x_test)\n",
    "mnb_accuracy = mnb.score(x_test, y_test)\n",
    "\n",
    "print 'Multinomial Naive Bayes Accuracy:', mnb_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_b = train[['Review','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random \n",
    "rows = random.sample(train_b.index, 6000)\n",
    "df_6000 = train_b.ix[rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descriptions = []\n",
    "pay = []\n",
    "\n",
    "for index, value in df_6000.iterrows():\n",
    "    descriptions.append(value['Review'])\n",
    "    pay.append(value['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data into test/training set\n",
    "trainset_size = int(round(len(df_6000)*0.75))\n",
    "\n",
    "X_train = np.array([''.join(el) for el in descriptions[0:trainset_size]])\n",
    "y_train = np.array([el for el in pay[0:trainset_size]])\n",
    "\n",
    "X_test = np.array([''.join(el) for el in descriptions[trainset_size+1:len(descriptions)]]) \n",
    "y_test = np.array([el for el in pay[trainset_size+1:len(pay)]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.838624338624\n",
      "Recall: 0.936945812808\n",
      "Accuracy: 0.835223482322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = 'english',   \\\n",
    "                             max_features = None)\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "#Run Naive Bayes Classifier\n",
    "nb_classifier = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_nb_predicted = nb_classifier.predict(X_test)\n",
    "\n",
    "print 'Precision:' + str(metrics.precision_score(y_test, y_nb_predicted, average = 'binary', pos_label='high'))\n",
    "print 'Recall: ' + str(metrics.recall_score(y_test, y_nb_predicted, average = 'binary', pos_label='high'))\n",
    "print 'Accuracy: ' + str(metrics.accuracy_score(y_test, y_nb_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing for any tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+') #Tokenizes and removes punctuation\n",
    "\n",
    "#Strip and decode FullDescription column so we can tokenize it\n",
    "df_6000['tokenized_strip'] = df_6000.apply(lambda row: row['Review'].decode('utf-8').strip(),axis=1)\n",
    "df_6000['tokenized'] = df_6000.apply(lambda row: tokenizer.tokenize(row['tokenized_strip']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Combine each row of tokens into one list\n",
    "tokens_series = pd.Series(df_6000['tokenized'])\n",
    "tokens_list = tokens_series.tolist()\n",
    "\n",
    "#Remove stop words and make all tokens lower case\n",
    "tokens = []\n",
    "for sentence in tokens_list:\n",
    "    for word in sentence:\n",
    "        if word.lower() not in stopwords.words('english'):\n",
    "            tokens.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
